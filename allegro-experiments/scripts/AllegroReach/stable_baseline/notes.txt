OrderedDict([('achieved_goal', array([ 0.4008276 , -0.0685866 , -0.22774519,  0.05827878,  0.47759697,
        0.7327185 ,  2.4765387 , -0.8607227 ,  0.89627784, -0.3062557 ,
       -0.60894597, -1.4110374 ], dtype=float32)), ('desired_goal', array([-1.005679  ,  0.34147817,  0.9540531 ,  1.1987132 ,  0.37403303,
        0.32209057,  0.31095287, -2.1119647 ,  0.82215786, -0.6675792 ,
       -1.5640837 ,  0.7348459 ], dtype=float32)), ('observation', array([-0.39490733, -0.67843455, -0.43765455,  0.1409685 , -0.67161006,
        1.3106273 ,  0.04009145, -1.714885  , -1.7085567 , -0.44895488,
       -0.6111999 , -1.9730839 ,  0.93647414,  0.2714189 , -0.67204314,
        0.8948596 , -0.14034131,  1.0312599 , -1.2369561 , -0.2345652 ,
       -0.17095046,  0.36576194,  0.9939435 , -1.0381949 , -1.2953175 ,
        1.4120669 , -0.23294891,  0.30627772, -1.2250876 , -0.35871807,
        1.3074456 , -1.060916  , -2.451866  ,  0.18679707,  0.609564  ,
       -0.16821782, -0.8448521 , -1.0025802 ,  0.6878543 , -2.1562986 ,
        0.6426088 ,  1.386251  ,  1.0454125 , -2.2426984 ], dtype=float32))])




Traceback (most recent call last):
  File "PPO.py", line 62, in <module>
    model.learn(total_timesteps=25000)
  File "/home/yb1025/.conda/envs/allegro_gym/lib/python3.6/site-packages/stable_baselines3/a2c/a2c.py", line 199, in learn
    reset_num_timesteps=reset_num_timesteps,
  File "/home/yb1025/.conda/envs/allegro_gym/lib/python3.6/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 227, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
  File "/home/yb1025/.conda/envs/allegro_gym/lib/python3.6/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 158, in collect_rollouts
    obs_tensor = th.as_tensor(self._last_obs).to(self.device)
RuntimeError: Could not infer dtype of collections.OrderedDict
~         

CONTENT
[ 1.43405125e-01  3.20282083e-01  7.12605361e-01  6.70528100e-01
  2.46444304e-04  3.15265525e-01  7.65980031e-01  7.32315690e-01
 -1.36155347e-01  3.98720304e-01  7.41557001e-01  7.04096379e-01
  3.67382383e-03  5.50629144e-01 -1.52292236e-03 -7.89488302e-01
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  9.38403697e-01  1.15942272e+00  2.13177318e-01  9.99981023e-01
  1.16013167e+00  2.14182569e-01  1.06098918e+00  1.16733792e+00
  2.19492613e-01  8.56612542e-01  1.35293760e+00  1.40993282e-01]
[0.9384037  1.15942272 0.21317732 0.99998102 1.16013167 0.21418257
 1.06098918 1.16733792 0.21949261 0.85661254 1.3529376  0.14099328]
[0.9384037  1.15942272 0.21317732 0.99462533 1.14811555 0.16594431
 1.06098918 1.16733792 0.21949261 0.88504918 1.31352355 0.15273595]
SHAPES
(44,)
(12,)
(12,)
~                                                                                                        
~           





Traceback (most recent call last):
  File "PPO.py", line 48, in <module>
    env = gym.make('AllegroReach-v0')
  File "/home/yb1025/.conda/envs/allegro_gym/lib/python3.6/site-packages/gym/envs/registration.py", line 145, in make
    return registry.make(id, **kwargs)
  File "/home/yb1025/.conda/envs/allegro_gym/lib/python3.6/site-packages/gym/envs/registration.py", line 90, in make
    env = spec.make(**kwargs)
  File "/home/yb1025/.conda/envs/allegro_gym/lib/python3.6/site-packages/gym/envs/registration.py", line 60, in make
    env = cls(**_kwargs)
  File "/home/yb1025/Research/PintoLab/allegro-gym/allegro_gym/envs/robotics/allegro/reach.py", line 58, in __init__
    relative_control=relative_control)
  File "/home/yb1025/Research/PintoLab/allegro-gym/allegro_gym/envs/robotics/allegro_env.py", line 23, in __init__
    initial_qpos=initial_qpos)
  File "/home/yb1025/Research/PintoLab/allegro-gym/allegro_gym/envs/robotics/allegro_robot_env.py", line 44, in __init__
    desired_goal=spaces.Box(-np.inf, np.inf, shape=obs['achieved_goal'].shape, dtype='float32'),
IndexError: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices
~                                                                                                        
~                                                                                                        
~                      




FIRST IS OBSERVATION spaces
SECOND IS ACTION SPACE

Allegro Reach Env
Dict(achieved_goal:Box(-inf, inf, (12,), float32), desired_goal:Box(-inf, inf, (12,), float32), observation:Box(-inf, inf, (44,), float32))
Box(-1.0, 1.0, (16,), float32)
Using cpu device
Wrapping the env with a `Monitor` wrapper
Wrapping the env in a DummyVecEnv.

Cartpole
Box(-3.4028234663852886e+38, 3.4028234663852886e+38, (4,), float32)
Discrete(2)